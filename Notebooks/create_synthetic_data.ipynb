{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac2dd946-a8d1-4112-8e61-558306a03464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data size: 102\n",
      "Saved synthetic data (cluster) for MVTec-AD_toothbrush in folder 'f\"./Synthetic_Datasets/global_outliers_datasets/'\n",
      "Original data size: 313\n",
      "Saved synthetic data (cluster) for MVTec-AD_transistor in folder 'f\"./Synthetic_Datasets/global_outliers_datasets/'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from copulas.multivariate import VineCopula\n",
    "from copulas.univariate import GaussianKDE\n",
    "import numpy as np\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "\n",
    "output_folder_cluster = '/Synthetic_Datasets/cluster_outliers_datasets/'  # Folder for cluster data\n",
    "output_folder_local = '/Synthetic_Datasets/local_outliers_datasets/'\n",
    "output_folder_global = '/Synthetic_Datasets/global_outliers_datasets/'\n",
    "output_folder_dependency = '/Synthetic_Datasets/dependency_outliers_datasets/'\n",
    "\n",
    "os.makedirs(output_folder_cluster, exist_ok=True)\n",
    "os.makedirs(output_folder_local, exist_ok=True)\n",
    "os.makedirs(output_folder_global, exist_ok=True)\n",
    "os.makedirs(output_folder_dependency, exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "# Dataset links\n",
    "dataset_links = {\n",
    "    'Classical': 'ADBench/adbench/datasets/Classical/',\n",
    "    'NLP': 'ADBench/adbench/datasets/NLP_by_BERT/',\n",
    "    'CV': 'ADBench/adbench/datasets/CV_by_ResNet18/'\n",
    "}\n",
    "\n",
    "dataset_name1 = np.array(['1_ALOI', '2_annthyroid', '3_backdoor', '4_breastw', '5_campaign',\n",
    "       '6_cardio', '7_Cardiotocography', '8_celeba', '9_census', '10_cover', '11_donors', '12_fault', '13_fraud', '14_glass',\n",
    "       '15_Hepatitis', '16_http', '17_InternetAds', '18_Ionosphere', '19_landsat', '20_letter',\n",
    "       '21_Lymphography', '22_magic.gamma', '23_mammography',\n",
    "       '24_mnist', '25_musk', '26_optdigits', '27_PageBlocks',\n",
    "       '28_pendigits', '29_Pima', '30_satellite',\n",
    "       '31_satimage-2', '32_shuttle','33_skin', '34_smtp', '35_SpamBase',\n",
    "       '36_speech', '37_Stamps', '38_thyroid', '39_vertebral',\n",
    "       '40_vowels', '41_Waveform', '42_WBC', '43_WDBC', '44_Wilt',\n",
    "       '45_wine', '46_WPBC', '47_yeast'])\n",
    "\n",
    "\n",
    "dataset_name2 = np.array([ '20news_0','20news_1','20news_2','20news_3','20news_4','20news_5',\n",
    "                         'agnews_0','agnews_1','agnews_2','agnews_3','amazon', 'imdb','yelp'])\n",
    "\n",
    "dataset_name3 = np.array([ 'CIFAR10_0','CIFAR10_1','CIFAR10_2','CIFAR10_3','CIFAR10_4','CIFAR10_5','CIFAR10_6','CIFAR10_7',\n",
    "        'CIFAR10_8','CIFAR10_9','FashionMNIST_0','FashionMNIST_1','FashionMNIST_2','FashionMNIST_3','FashionMNIST_4','FashionMNIST_5',\n",
    "        'FashionMNIST_6','FashionMNIST_7','FashionMNIST_8','FashionMNIST_9','SVHN_0','SVHN_1','SVHN_2','SVHN_3','SVHN_4',\n",
    "        'SVHN_5','SVHN_6','SVHN_7','SVHN_8','SVHN_9','MNIST-C_brightness', 'MNIST-C_canny_edges','MNIST-C_dotted_line', 'MNIST-C_fog',\n",
    "        'MNIST-C_glass_blur','MNIST-C_identity','MNIST-C_impulse_noise','MNIST-C_motion_blur','MNIST-C_rotate','MNIST-C_scale','MNIST-C_shear',\n",
    "        'MNIST-C_shot_noise','MNIST-C_spatter','MNIST-C_stripe','MNIST-C_translate','MNIST-C_zigzag','MVTec-AD_bottle',\n",
    "        'MVTec-AD_cable','MVTec-AD_capsule','MVTec-AD_carpet','MVTec-AD_grid','MVTec-AD_hazelnut','MVTec-AD_leather',\n",
    "        'MVTec-AD_metal_nut','MVTec-AD_pill','MVTec-AD_screw','MVTec-AD_tile','MVTec-AD_toothbrush',\n",
    "        'MVTec-AD_transistor','MVTec-AD_wood','MVTec-AD_zipper'])\n",
    "\n",
    "__TYPES = \"global\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e50100f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_realistic_synthetic(X, y, realistic_synthetic_mode, alpha:int, percentage:float, seed:int=42):\n",
    "    '''\n",
    "    Currently, four types of realistic synthetic outliers can be generated:\n",
    "    1. local outliers: where normal data follows the GMM distribution, and anomalies follow the GMM distribution with modified covariance\n",
    "    2. global outliers: where normal data follows the GMM distribution, and anomalies follow the uniform distribution\n",
    "    3. dependency outliers: where normal data follows the vine copula distribution, and anomalies follow the independent distribution captured by GaussianKDE\n",
    "    4. cluster outliers: where normal data follows the GMM distribution, and anomalies follow the GMM distribution with modified mean\n",
    "\n",
    "    :param X: input X\n",
    "    :param y: input y\n",
    "    :param realistic_synthetic_mode: the type of generated outliers\n",
    "    :param alpha: the scaling parameter for controlling the generated local and cluster anomalies\n",
    "    :param percentage: controlling the generated global anomalies\n",
    "    :param seed: random seed for reproducibility\n",
    "    '''\n",
    "\n",
    "    if realistic_synthetic_mode not in ['local', 'cluster', 'dependency', 'global']:\n",
    "        raise NotImplementedError(f\"Mode {realistic_synthetic_mode} is not implemented.\")\n",
    "\n",
    "    # the number of normal data and anomalies\n",
    "    pts_n = len(np.where(y == 0)[0])\n",
    "    pts_a = len(np.where(y == 1)[0])\n",
    "\n",
    "    # only use the normal data to fit the model\n",
    "    X_normal = X[y.values == 0]\n",
    "    y_normal = y[y == 0]\n",
    "\n",
    "    # generate the synthetic normal data\n",
    "    if realistic_synthetic_mode in ['local', 'cluster', 'global']:\n",
    "        # select the best n_components based on the BIC value\n",
    "        metric_list = []\n",
    "        n_components_list = list(np.arange(1, 10))\n",
    "\n",
    "        for n_components in n_components_list:\n",
    "            gm = GaussianMixture(n_components=n_components, random_state=seed).fit(X_normal)\n",
    "            metric_list.append(gm.bic(X_normal))\n",
    "\n",
    "        best_n_components = n_components_list[np.argmin(metric_list)]\n",
    "\n",
    "        # refit based on the best n_components\n",
    "        gm = GaussianMixture(n_components=best_n_components, random_state=seed).fit(X_normal)\n",
    "\n",
    "        # generate the synthetic normal data\n",
    "        X_synthetic_normal = gm.sample(pts_n)[0]\n",
    "\n",
    "    elif realistic_synthetic_mode == 'dependency':\n",
    "        # sampling the feature since copulas method may spend too long to fit\n",
    "        if X.shape[1] > 50:\n",
    "            idx = np.random.choice(np.arange(X.shape[1]), 50, replace=False)\n",
    "            X_normal = X_normal[:, idx]\n",
    "      \n",
    "        copula = VineCopula('center')  # default is the C-vine copula\n",
    "        if X_normal.shape[0] > 2000:\n",
    "            X_sampled = X_normal.sample(n=2000, random_state=42)  # Sample 2000 rows\n",
    "        else:\n",
    "            X_sampled = X_normal  # Use all rows if there are fewer than 2000\n",
    "        copula.fit(pd.DataFrame(X_sampled))\n",
    "       \n",
    "        # sample to generate synthetic normal data\n",
    "        X_synthetic_normal = copula.sample(pts_n).values\n",
    "        print(X_synthetic_normal)\n",
    "       \n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    # generate the synthetic abnormal data\n",
    "    if realistic_synthetic_mode == 'local':\n",
    "        # generate the synthetic anomalies (local outliers)\n",
    "        gm.covariances_ = alpha * gm.covariances_\n",
    "        X_synthetic_anomalies = gm.sample(pts_a)[0]\n",
    "\n",
    "    elif realistic_synthetic_mode == 'cluster':\n",
    "        # generate the clustering synthetic anomalies\n",
    "        gm.means_ = alpha * gm.means_\n",
    "        X_synthetic_anomalies = gm.sample(pts_a)[0]\n",
    "\n",
    "    elif realistic_synthetic_mode == 'dependency':\n",
    "        print(\"helo\")\n",
    "        X_synthetic_anomalies = np.zeros((pts_a, X_normal.shape[1]))\n",
    "        print(\"helo\")\n",
    "        \n",
    "        # using the GaussianKDE for generating independent features\n",
    "        for i in range(X_normal.shape[1]):\n",
    "            kde = GaussianKDE()\n",
    "            kde.fit(X_normal.iloc[:, i])  # Use .iloc to index columns by position\n",
    "            X_synthetic_anomalies[:, i] = kde.sample(pts_a)\n",
    "        print(\"helo\")\n",
    "    elif realistic_synthetic_mode == 'global':\n",
    "        # generate the synthetic anomalies (global outliers)\n",
    "        X_synthetic_anomalies = []\n",
    "\n",
    "        for i in range(X_synthetic_normal.shape[1]):\n",
    "            low = np.min(X_synthetic_normal[:, i]) * (1 + percentage)\n",
    "            high = np.max(X_synthetic_normal[:, i]) * (1 + percentage)\n",
    "\n",
    "            X_synthetic_anomalies.append(np.random.uniform(low=low, high=high, size=pts_a))\n",
    "\n",
    "        X_synthetic_anomalies = np.array(X_synthetic_anomalies).T\n",
    "\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    # Concatenate normal and anomalous data\n",
    "    X_combined = np.concatenate((X_synthetic_normal, X_synthetic_anomalies), axis=0)\n",
    "    y_combined = np.append(np.repeat(0, X_synthetic_normal.shape[0]),\n",
    "                           np.repeat(1, X_synthetic_anomalies.shape[0]))\n",
    "\n",
    "    return X_combined, y_combined\n",
    "\n",
    "\n",
    "\n",
    "# Function to load and process the dataset\n",
    "def load_and_process_dataset(name, domain):\n",
    "    try:\n",
    "        dataset_path = f\"{dataset_links[domain]}{name}.npz\"\n",
    "        data = np.load(dataset_path, allow_pickle=True)\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {domain} dataset {name}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b94d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over datasets and generate synthetic data\n",
    "for dataset_array, domain in zip([dataset_name1, dataset_name2, dataset_name3], ['Classical', 'NLP', 'CV']):\n",
    "    for name in dataset_array:\n",
    "        data = load_and_process_dataset(name, domain)\n",
    "        if data is None:\n",
    "            continue  # Skip if dataset couldn't be loaded\n",
    "\n",
    "        try:\n",
    "            X, y = data['X'], data['y']\n",
    "            X, y = pd.DataFrame(X), pd.DataFrame(y)\n",
    "            print(\"Original data size:\", len(y))\n",
    "    \n",
    "            # Reduce data size if too large\n",
    "            if len(y) > 10000:\n",
    "                print(\"Reducing data size to 10000\")\n",
    "                _, X, _, y = train_test_split(X, y, test_size=10000, random_state=42)\n",
    "    \n",
    "            # Generate synthetic data for data __TYPES\n",
    "            if __TYPES == 'global':\n",
    "                X_gen, y_gen = generate_realistic_synthetic(X, y, \"global\", alpha=1.1, percentage=0.1)\n",
    "            if __TYPES == 'cluster':\n",
    "                X_gen, y_gen = generate_realistic_synthetic(X, y, \"cluster\", alpha=1.1, percentage=0.1)\n",
    "            if __TYPES == 'local':\n",
    "                X_gen, y_gen = generate_realistic_synthetic(X, y, \"local\", alpha=1.1, percentage=0.1)\n",
    "            if __TYPES == 'dependency':\n",
    "                X_gen, y_gen = generate_realistic_synthetic(X, y, \"dependency\", alpha=1.1, percentage=0.1)\n",
    "            \n",
    "    \n",
    "            # Convert the synthetic data to DataFrame before saving\n",
    "            X_gen_df = pd.DataFrame(X_gen)\n",
    "            y_gen_df = pd.DataFrame(y_gen)\n",
    "    \n",
    "            # Save synthetic data for data __TYPES\n",
    "            # output_folder_cluster \n",
    "            # output_folder_local\n",
    "            # output_folder_global \n",
    "            # output_folder_dependency \n",
    "            if __TYPES == 'global':\n",
    "                output_filename_X= os.path.join(output_folder_global, f'{name}_X.csv')\n",
    "                output_filename_y = os.path.join(output_folder_global, f'{name}_y.csv')\n",
    "            if __TYPES == 'cluster':\n",
    "                output_filename_X= os.path.join(output_folder_cluster, f'{name}_X.csv')\n",
    "                output_filename_y = os.path.join(output_folder_cluster, f'{name}_y.csv')\n",
    "            if __TYPES == 'local':\n",
    "                output_filename_X= os.path.join(output_folder_local, f'{name}_X.csv')\n",
    "                output_filename_y = os.path.join(output_folder_local, f'{name}_y.csv')\n",
    "            if __TYPES == 'dependency':\n",
    "                output_filename_X= os.path.join(output_folder_dependency, f'{name}_X.csv')\n",
    "                output_filename_y = os.path.join(output_folder_dependency, f'{name}_y.csv')\n",
    "            \n",
    "    \n",
    "            X_gen_df.to_csv(output_filename_X, index=False)\n",
    "            y_gen_df.to_csv(output_filename_y, index=False)\n",
    "    \n",
    "            print(f\"Saved synthetic data for {name} in folder\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing dataset {name}: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
